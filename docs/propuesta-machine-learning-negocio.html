<!DOCTYPE html>
<html lang="es">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Machine Learning Implementation - Parse</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            line-height: 1.6;
            color: #333;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            padding: 20px;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            background: white;
            border-radius: 10px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.2);
            overflow: hidden;
        }

        header {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 40px;
            text-align: center;
        }

        header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .content {
            padding: 40px;
        }

        h2 {
            color: #667eea;
            border-bottom: 3px solid #667eea;
            padding-bottom: 10px;
            margin: 40px 0 20px 0;
            font-size: 2em;
        }

        h3 {
            color: #764ba2;
            margin: 30px 0 15px 0;
            font-size: 1.5em;
        }

        h4 {
            color: #555;
            margin: 20px 0 10px 0;
            font-size: 1.2em;
        }

        .section {
            margin-bottom: 40px;
        }

        .card {
            background: #f8f9fa;
            border-left: 4px solid #667eea;
            padding: 20px;
            margin: 20px 0;
            border-radius: 5px;
        }

        .card.warning {
            border-left-color: #ffc107;
            background: #fff9e6;
        }

        .card.success {
            border-left-color: #28a745;
            background: #e8f5e9;
        }

        .card.info {
            border-left-color: #17a2b8;
            background: #e3f2fd;
        }

        code {
            background: #f4f4f4;
            padding: 2px 6px;
            border-radius: 3px;
            font-family: 'Courier New', monospace;
            color: #e83e8c;
        }

        pre {
            background: #2d2d2d;
            color: #f8f8f2;
            padding: 20px;
            border-radius: 5px;
            overflow-x: auto;
            margin: 20px 0;
            font-size: 0.9em;
        }

        pre code {
            background: none;
            color: inherit;
            padding: 0;
        }

        .grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .box {
            background: white;
            border: 2px solid #e0e0e0;
            padding: 20px;
            border-radius: 8px;
            transition: transform 0.3s, box-shadow 0.3s;
        }

        .box:hover {
            transform: translateY(-5px);
            box-shadow: 0 5px 20px rgba(0,0,0,0.1);
        }

        .box h4 {
            color: #667eea;
            margin-top: 0;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin: 20px 0;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }

        th {
            background: #667eea;
            color: white;
            padding: 15px;
            text-align: left;
        }

        td {
            padding: 12px 15px;
            border-bottom: 1px solid #ddd;
        }

        tr:hover {
            background: #f5f5f5;
        }

        .badge {
            display: inline-block;
            padding: 5px 10px;
            border-radius: 20px;
            font-size: 0.85em;
            font-weight: bold;
            margin: 5px;
        }

        .badge.high {
            background: #dc3545;
            color: white;
        }

        .badge.medium {
            background: #ffc107;
            color: #333;
        }

        .badge.low {
            background: #28a745;
            color: white;
        }

        .timeline {
            position: relative;
            padding-left: 40px;
            margin: 30px 0;
        }

        .timeline::before {
            content: '';
            position: absolute;
            left: 10px;
            top: 0;
            height: 100%;
            width: 3px;
            background: #667eea;
        }

        .timeline-item {
            position: relative;
            margin-bottom: 30px;
        }

        .timeline-item::before {
            content: '';
            position: absolute;
            left: -34px;
            top: 5px;
            width: 15px;
            height: 15px;
            border-radius: 50%;
            background: #667eea;
            border: 3px solid white;
            box-shadow: 0 0 0 3px #667eea;
        }

        .architecture-diagram {
            background: #f8f9fa;
            padding: 30px;
            border-radius: 10px;
            margin: 30px 0;
            font-family: monospace;
            text-align: center;
        }

        .flow-box {
            display: inline-block;
            padding: 15px 25px;
            background: white;
            border: 2px solid #667eea;
            border-radius: 8px;
            margin: 10px;
            font-weight: bold;
        }

        .arrow {
            font-size: 2em;
            color: #667eea;
            margin: 0 10px;
        }

        ul, ol {
            margin-left: 20px;
            margin-bottom: 15px;
        }

        li {
            margin: 10px 0;
        }

        .highlight {
            background: linear-gradient(120deg, #84fab0 0%, #8fd3f4 100%);
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
        }

        footer {
            background: #2d2d2d;
            color: white;
            padding: 20px;
            text-align: center;
        }
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>🤖 Machine Learning para Parse</h1>
            <p>Guía Completa de Implementación y Arquitectura</p>
        </header>

        <div class="content">
            <!-- Introducción -->
            <section class="section">
                <h2>📋 Resumen Ejecutivo</h2>
                <div class="card info">
                    <p><strong>Objetivo:</strong> Integrar Machine Learning en Parse para mejorar la precisión de extracción de comprobantes, automatizar clasificaciones y detectar anomalías, reduciendo intervención manual en un 70%.</p>
                </div>

                <div class="grid">
                    <div class="box">
                        <h4>🎯 Beneficios</h4>
                        <ul>
                            <li>95%+ precisión en clasificación</li>
                            <li>Reducción de errores de extracción</li>
                            <li>Aprendizaje continuo</li>
                            <li>Detección automática de fraudes</li>
                        </ul>
                    </div>
                    <div class="box">
                        <h4>⚙️ Tecnologías</h4>
                        <ul>
                            <li>Python (scikit-learn, TensorFlow)</li>
                            <li>FastAPI (ML API)</li>
                            <li>PostgreSQL (feature store)</li>
                            <li>MLflow (tracking)</li>
                        </ul>
                    </div>
                    <div class="box">
                        <h4>📊 Métricas Objetivo</h4>
                        <ul>
                            <li>Accuracy: >95%</li>
                            <li>Precision: >90%</li>
                            <li>Recall: >90%</li>
                            <li>Latencia: <500ms</li>
                        </ul>
                    </div>
                </div>
            </section>

            <!-- Casos de Uso -->
            <section class="section">
                <h2>🎯 Casos de Uso de ML en Parse</h2>

                <h3>1. Clasificación Automática de Comprobantes</h3>
                <div class="card">
                    <h4>Problema Actual</h4>
                    <p>Gemini clasifica con prompts, pero puede fallar con formatos no estándar o escaneos de baja calidad.</p>

                    <h4>Solución ML</h4>
                    <p>Modelo de clasificación entrenado con documentos reales del sistema:</p>
                    <ul>
                        <li><strong>Input:</strong> Imagen/PDF del documento</li>
                        <li><strong>Output:</strong> Tipo (Factura A/B/C, NC, ND, Remito, Recibo, Despacho)</li>
                        <li><strong>Modelo:</strong> CNN (Convolutional Neural Network) o Random Forest sobre features extraídas</li>
                        <li><strong>Precisión esperada:</strong> 97%+</li>
                    </ul>
                </div>

                <h3>2. Extracción Inteligente de Campos (NER)</h3>
                <div class="card success">
                    <h4>Named Entity Recognition para Comprobantes</h4>
                    <p>Entrenar modelo que detecte entidades específicas:</p>

                    <table>
                        <thead>
                            <tr>
                                <th>Entidad</th>
                                <th>Ejemplo</th>
                                <th>Patrón a Aprender</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td><code>CUIT</code></td>
                                <td>20-12345678-9</td>
                                <td>Formato NN-NNNNNNNN-N</td>
                            </tr>
                            <tr>
                                <td><code>FECHA</code></td>
                                <td>15/03/2024</td>
                                <td>Contexto: "Fecha:", "Emisión"</td>
                            </tr>
                            <tr>
                                <td><code>TOTAL</code></td>
                                <td>$ 150.500,00</td>
                                <td>Contexto: "Total", "Importe"</td>
                            </tr>
                            <tr>
                                <td><code>CAE</code></td>
                                <td>72155891234567</td>
                                <td>14 dígitos numéricos</td>
                            </tr>
                            <tr>
                                <td><code>PROVEEDOR</code></td>
                                <td>ACME S.A.</td>
                                <td>Contexto: encabezado, CUIT emisor</td>
                            </tr>
                        </tbody>
                    </table>

                    <p><strong>Herramienta:</strong> spaCy con modelo custom entrenado en español argentino</p>
                </div>

                <h3>3. Detección de Anomalías</h3>
                <div class="card warning">
                    <h4>Casos a Detectar</h4>
                    <ul>
                        <li>🚨 <strong>Facturas duplicadas:</strong> Mismo CAE, mismo proveedor</li>
                        <li>🚨 <strong>Montos atípicos:</strong> Valores fuera del rango histórico</li>
                        <li>🚨 <strong>Fechas inválidas:</strong> Fechas futuras, muy antiguas</li>
                        <li>🚨 <strong>CUIT inexistente:</strong> Validación contra base AFIP</li>
                        <li>🚨 <strong>Patrones de fraude:</strong> Secuencia sospechosa de operaciones</li>
                    </ul>

                    <p><strong>Algoritmo:</strong> Isolation Forest o Autoencoder</p>
                </div>

                <h3>4. Autocompletado Inteligente</h3>
                <div class="card">
                    <h4>Predicción de Metadatos</h4>
                    <p>Basado en documentos similares procesados:</p>
                    <ul>
                        <li><strong>Centro de costos:</strong> Predecir según proveedor + descripción</li>
                        <li><strong>Categoría contable:</strong> Machine learning sobre histórico</li>
                        <li><strong>Cuenta contable:</strong> Sugerencias basadas en items</li>
                        <li><strong>Proyecto/Obra:</strong> Inferir según contexto</li>
                    </ul>
                    <p><strong>Modelo:</strong> Random Forest Classifier o Gradient Boosting</p>
                </div>

                <h3>5. Mejora de OCR con Post-Processing</h3>
                <div class="card info">
                    <h4>Corrección de Errores de OCR</h4>
                    <p>Modelo que corrija errores típicos de OCR en texto español:</p>
                    <ul>
                        <li>"0" → "O" en texto</li>
                        <li>"l" → "1" en números</li>
                        <li>Espacios faltantes en CUIT</li>
                        <li>Símbolos mal interpretados ($, -, /)</li>
                    </ul>
                    <p><strong>Técnica:</strong> Seq2Seq model o Transformer fine-tuned</p>
                </div>
            </section>

            <!-- Arquitectura -->
            <section class="section">
                <h2>🏗️ Arquitectura Propuesta</h2>

                <div class="architecture-diagram">
                    <div class="flow-box">Frontend<br>(Next.js)</div>
                    <span class="arrow">→</span>
                    <div class="flow-box">API Gateway<br>(Node.js/Express)</div>
                    <span class="arrow">→</span>
                    <div class="flow-box">ML Service<br>(FastAPI/Python)</div>
                    <br><br>
                    <span class="arrow">↓</span>
                    <br>
                    <div class="flow-box">ML Models<br>(TensorFlow/scikit-learn)</div>
                    <span class="arrow">↔</span>
                    <div class="flow-box">Feature Store<br>(PostgreSQL)</div>
                    <span class="arrow">↔</span>
                    <div class="flow-box">Model Registry<br>(MLflow)</div>
                </div>

                <h3>Componentes Nuevos</h3>

                <h4>1. ML Service (FastAPI)</h4>
                <pre><code># ml-service/app/main.py
from fastapi import FastAPI, File, UploadFile
from models import ClassifierModel, NERModel, AnomalyDetector
import numpy as np
from PIL import Image
import io

app = FastAPI(title="Parse ML Service")

# Cargar modelos al inicio
classifier = ClassifierModel.load("models/classifier_v1.pkl")
ner_model = NERModel.load("models/ner_model")
anomaly_detector = AnomalyDetector.load("models/anomaly_v1.pkl")

@app.post("/classify")
async def classify_document(file: UploadFile = File(...)):
    """
    Clasifica tipo de comprobante.
    Input: PDF o imagen
    Output: {type: 'factura_a', confidence: 0.98}
    """
    contents = await file.read()
    image = Image.open(io.BytesIO(contents))

    prediction = classifier.predict(image)

    return {
        "document_type": prediction["class"],
        "confidence": float(prediction["confidence"]),
        "probabilities": prediction["all_probs"]
    }

@app.post("/extract")
async def extract_entities(text: str):
    """
    Extrae entidades del texto OCR.
    Input: Texto extraído por OCR
    Output: {cuit: '20-12345678-9', fecha: '15/03/2024', ...}
    """
    entities = ner_model.extract(text)

    return {
        "entities": entities,
        "confidence_scores": ner_model.get_confidence(text, entities)
    }

@app.post("/detect-anomalies")
async def detect_anomalies(document_data: dict):
    """
    Detecta anomalías en el documento.
    Input: Datos extraídos del documento
    Output: {is_anomaly: false, anomaly_score: 0.15, flags: []}
    """
    features = extract_features(document_data)
    result = anomaly_detector.predict(features)

    return {
        "is_anomaly": result["is_anomaly"],
        "anomaly_score": float(result["score"]),
        "flags": result["detected_issues"],
        "similar_documents": result["similar_docs"]
    }

@app.post("/predict-metadata")
async def predict_metadata(document_data: dict):
    """
    Predice metadatos basado en contenido.
    Input: Datos del documento (proveedor, items, etc)
    Output: {centro_costo: 'CC001', categoria: 'SERVICIOS', ...}
    """
    predictions = {
        "centro_costo": predict_cost_center(document_data),
        "categoria_contable": predict_category(document_data),
        "cuenta_contable": predict_account(document_data),
        "confidence_scores": get_prediction_confidence()
    }

    return predictions
</code></pre>

                <h4>2. Integración en Backend Node.js</h4>
                <pre><code>// backend/src/services/mlService.js
const axios = require('axios');

const ML_SERVICE_URL = process.env.ML_SERVICE_URL || 'http://localhost:8000';

class MLService {
  async classifyDocument(fileBuffer) {
    const formData = new FormData();
    formData.append('file', fileBuffer);

    const response = await axios.post(`${ML_SERVICE_URL}/classify`, formData, {
      headers: { 'Content-Type': 'multipart/form-data' }
    });

    return response.data;
  }

  async extractEntities(ocrText) {
    const response = await axios.post(`${ML_SERVICE_URL}/extract`, {
      text: ocrText
    });

    return response.data.entities;
  }

  async detectAnomalies(documentData) {
    const response = await axios.post(`${ML_SERVICE_URL}/detect-anomalies`,
      documentData
    );

    return response.data;
  }

  async predictMetadata(documentData) {
    const response = await axios.post(`${ML_SERVICE_URL}/predict-metadata`,
      documentData
    );

    return response.data;
  }
}

module.exports = new MLService();
</code></pre>

                <h4>3. Flujo de Procesamiento Mejorado</h4>
                <pre><code>// backend/src/services/documentProcessor.js
const mlService = require('./mlService');
const geminiService = require('./geminiService');

async function processDocumentWithML(fileBuffer, documentId) {
  try {
    // Fase 1: Clasificación con ML
    console.log('🤖 Clasificando con ML...');
    const mlClassification = await mlService.classifyDocument(fileBuffer);

    let documentType = mlClassification.document_type;
    let classificationMethod = 'ml';

    // Fallback a Gemini si confianza es baja
    if (mlClassification.confidence < 0.85) {
      console.log('⚠️ Confianza ML baja, usando Gemini...');
      const geminiClassification = await geminiService.classify(fileBuffer);
      documentType = geminiClassification.type;
      classificationMethod = 'gemini_fallback';
    }

    // Fase 2: OCR
    const ocrText = await performOCR(fileBuffer);

    // Fase 3: Extracción con ML (NER)
    console.log('🔍 Extrayendo entidades con NER...');
    const mlEntities = await mlService.extractEntities(ocrText);

    // Fase 4: Extracción con Gemini (más completa)
    const geminiExtraction = await geminiService.extractData(
      fileBuffer,
      documentType
    );

    // Fase 5: Merge inteligente de resultados
    const mergedData = mergeExtractionResults(mlEntities, geminiExtraction);

    // Fase 6: Predicción de metadatos
    const predictedMetadata = await mlService.predictMetadata(mergedData);

    // Fase 7: Detección de anomalías
    const anomalyCheck = await mlService.detectAnomalies(mergedData);

    if (anomalyCheck.is_anomaly) {
      console.warn('🚨 Anomalía detectada:', anomalyCheck.flags);
      await notifyAnomalyDetected(documentId, anomalyCheck);
    }

    // Fase 8: Guardar con metadata enriquecida
    await saveDocument({
      ...mergedData,
      document_type: documentType,
      classification_method: classificationMethod,
      ml_confidence: mlClassification.confidence,
      predicted_metadata: predictedMetadata,
      anomaly_score: anomalyCheck.anomaly_score,
      anomaly_flags: anomalyCheck.flags
    });

    return {
      success: true,
      data: mergedData,
      metadata: {
        classification: mlClassification,
        predictions: predictedMetadata,
        anomalies: anomalyCheck
      }
    };

  } catch (error) {
    console.error('Error en procesamiento ML:', error);
    // Fallback completo a procesamiento tradicional
    return await processDocumentTraditional(fileBuffer, documentId);
  }
}
</code></pre>
            </section>

            <!-- Plan de Implementación -->
            <section class="section">
                <h2>📅 Plan de Implementación</h2>

                <div class="timeline">
                    <div class="timeline-item">
                        <h4>Fase 1: Preparación de Datos (2-3 semanas)</h4>
                        <span class="badge high">Crítico</span>
                        <ul>
                            <li>Exportar documentos procesados de <code>parse_db</code></li>
                            <li>Crear dataset etiquetado (mínimo 1000 documentos por tipo)</li>
                            <li>Split: 70% training, 15% validation, 15% test</li>
                            <li>Etiquetar manualmente casos edge para NER</li>
                        </ul>
                        <pre><code># Script de exportación
import prisma from '@prisma/client';
import fs from 'fs';

async function exportTrainingData() {
  const documents = await prisma.documentos_procesados.findMany({
    where: {
      estado: 'completado',
      document_type: { not: null }
    },
    include: {
      lineas: true,
      impuestos: true
    }
  });

  const dataset = documents.map(doc => ({
    file_path: doc.archivo_path,
    label: doc.document_type,
    extracted_data: doc.datos_extraidos,
    metadata: {
      proveedor: doc.proveedor,
      total: doc.total,
      fecha: doc.fecha
    }
  }));

  fs.writeFileSync('ml-training-data.json', JSON.stringify(dataset, null, 2));
}
</code></pre>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 2: Desarrollo del Clasificador (2 semanas)</h4>
                        <span class="badge medium">Importante</span>
                        <ul>
                            <li>Entrenar modelo de clasificación CNN</li>
                            <li>Evaluar métricas: accuracy, precision, recall</li>
                            <li>Optimizar hyperparámetros</li>
                            <li>Exportar modelo para producción</li>
                        </ul>
                        <pre><code># ml-service/training/train_classifier.py
import tensorflow as tf
from tensorflow.keras import layers, models
from sklearn.model_selection import train_test_split
import numpy as np

def build_classifier():
    model = models.Sequential([
        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(64, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(8, activation='softmax')  # 8 tipos de comprobantes
    ])

    model.compile(
        optimizer='adam',
        loss='categorical_crossentropy',
        metrics=['accuracy', 'precision', 'recall']
    )

    return model

# Entrenar
X_train, X_test, y_train, y_test = load_and_split_data()
model = build_classifier()

history = model.fit(
    X_train, y_train,
    epochs=50,
    batch_size=32,
    validation_data=(X_test, y_test),
    callbacks=[
        tf.keras.callbacks.EarlyStopping(patience=5),
        tf.keras.callbacks.ModelCheckpoint('best_classifier.h5')
    ]
)

# Evaluar
test_loss, test_acc, test_prec, test_rec = model.evaluate(X_test, y_test)
print(f'Accuracy: {test_acc:.2%}')
print(f'Precision: {test_prec:.2%}')
print(f'Recall: {test_rec:.2%}')
</code></pre>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 3: Modelo NER (3 semanas)</h4>
                        <span class="badge high">Crítico</span>
                        <ul>
                            <li>Anotar corpus con entidades (CUIT, fecha, total, CAE, etc)</li>
                            <li>Entrenar modelo spaCy custom</li>
                            <li>Validar con documentos reales</li>
                            <li>Fine-tune con errores comunes</li>
                        </ul>
                        <pre><code># ml-service/training/train_ner.py
import spacy
from spacy.training import Example
from spacy.util import minibatch

def train_ner_model():
    # Crear modelo base
    nlp = spacy.blank("es")
    ner = nlp.add_pipe("ner")

    # Agregar labels
    labels = ["CUIT", "FECHA", "TOTAL", "CAE", "PROVEEDOR", "ITEMS", "IVA"]
    for label in labels:
        ner.add_label(label)

    # Datos de entrenamiento anotados
    TRAIN_DATA = load_annotated_data()  # Formato: (text, {entities: [(start, end, label)]})

    # Entrenar
    optimizer = nlp.begin_training()
    for epoch in range(30):
        losses = {}
        batches = minibatch(TRAIN_DATA, size=8)
        for batch in batches:
            examples = [Example.from_dict(nlp.make_doc(text), annotations)
                       for text, annotations in batch]
            nlp.update(examples, drop=0.35, losses=losses)
        print(f"Epoch {epoch}, Loss: {losses['ner']:.2f}")

    # Guardar
    nlp.to_disk("models/ner_model")
    return nlp

# Ejemplo de uso
nlp = train_ner_model()
doc = nlp("CUIT: 20-12345678-9 Total: $150.500,00")
for ent in doc.ents:
    print(f"{ent.text} → {ent.label_}")
</code></pre>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 4: Detector de Anomalías (1-2 semanas)</h4>
                        <span class="badge medium">Importante</span>
                        <ul>
                            <li>Implementar Isolation Forest</li>
                            <li>Definir features relevantes</li>
                            <li>Entrenar con documentos normales</li>
                            <li>Validar con casos anómalos conocidos</li>
                        </ul>
                        <pre><code># ml-service/models/anomaly_detector.py
from sklearn.ensemble import IsolationForest
from sklearn.preprocessing import StandardScaler
import numpy as np

class AnomalyDetector:
    def __init__(self):
        self.model = IsolationForest(
            contamination=0.05,  # 5% de documentos esperados como anómalos
            random_state=42
        )
        self.scaler = StandardScaler()

    def extract_features(self, document):
        """Extraer features numéricas del documento"""
        return np.array([
            document['total'],
            document['subtotal'],
            document['iva_monto'],
            len(document['items']),
            document['cantidad_total_items'],
            document['dias_desde_emision'],
            document['monto_promedio_item'],
            # Features categóricas codificadas
            self.encode_tipo(document['tipo']),
            self.encode_proveedor(document['proveedor_id'])
        ]).reshape(1, -1)

    def train(self, normal_documents):
        """Entrenar solo con documentos normales"""
        features = np.array([
            self.extract_features(doc) for doc in normal_documents
        ])
        features_scaled = self.scaler.fit_transform(features)
        self.model.fit(features_scaled)

    def predict(self, document):
        """Predecir si un documento es anómalo"""
        features = self.extract_features(document)
        features_scaled = self.scaler.transform(features)

        prediction = self.model.predict(features_scaled)[0]
        score = self.model.score_samples(features_scaled)[0]

        is_anomaly = prediction == -1

        # Detectar qué tipo de anomalía
        flags = []
        if document['total'] > document['subtotal'] * 1.5:
            flags.append('MONTO_IVA_ALTO')
        if document['dias_desde_emision'] > 180:
            flags.append('FACTURA_ANTIGUA')
        if len(document['items']) == 0:
            flags.append('SIN_ITEMS')

        return {
            'is_anomaly': is_anomaly,
            'score': abs(score),
            'detected_issues': flags,
            'similar_docs': self.find_similar(document)
        }
</code></pre>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 5: ML Service (FastAPI) (1 semana)</h4>
                        <span class="badge low">Setup</span>
                        <ul>
                            <li>Crear API REST con FastAPI</li>
                            <li>Cargar modelos en memoria</li>
                            <li>Implementar endpoints</li>
                            <li>Dockerizar servicio</li>
                        </ul>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 6: Integración Backend (1 semana)</h4>
                        <span class="badge medium">Importante</span>
                        <ul>
                            <li>Conectar Node.js con ML Service</li>
                            <li>Implementar lógica de fallback</li>
                            <li>Agregar logs y monitoring</li>
                            <li>Testing end-to-end</li>
                        </ul>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 7: UI para ML Insights (1 semana)</h4>
                        <span class="badge low">Nice to have</span>
                        <ul>
                            <li>Dashboard de confianza de predicciones</li>
                            <li>Alertas de anomalías en tiempo real</li>
                            <li>Visualización de predicciones vs realidad</li>
                            <li>Feedback loop para reentrenamiento</li>
                        </ul>
                    </div>

                    <div class="timeline-item">
                        <h4>Fase 8: Deployment y Monitoreo (1 semana)</h4>
                        <span class="badge high">Crítico</span>
                        <ul>
                            <li>Deploy ML Service en producción</li>
                            <li>Configurar MLflow para tracking</li>
                            <li>Implementar A/B testing</li>
                            <li>Monitoreo de performance y drift</li>
                        </ul>
                    </div>
                </div>

                <div class="highlight">
                    <strong>Duración total estimada:</strong> 10-14 semanas (2.5-3.5 meses)<br>
                    <strong>Equipo requerido:</strong> 1 ML Engineer + 1 Backend Developer
                </div>
            </section>

            <!-- Stack Técnico -->
            <section class="section">
                <h2>🛠️ Stack Técnico Detallado</h2>

                <table>
                    <thead>
                        <tr>
                            <th>Componente</th>
                            <th>Tecnología</th>
                            <th>Justificación</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>ML Framework</strong></td>
                            <td>TensorFlow + scikit-learn</td>
                            <td>TensorFlow para CNNs, sklearn para modelos clásicos</td>
                        </tr>
                        <tr>
                            <td><strong>NER/NLP</strong></td>
                            <td>spaCy 3.x</td>
                            <td>Best-in-class para NER en español, extensible</td>
                        </tr>
                        <tr>
                            <td><strong>API Service</strong></td>
                            <td>FastAPI</td>
                            <td>Rápido, async, auto-docs, typed Python</td>
                        </tr>
                        <tr>
                            <td><strong>Model Registry</strong></td>
                            <td>MLflow</td>
                            <td>Versionado, tracking, deployment</td>
                        </tr>
                        <tr>
                            <td><strong>Feature Store</strong></td>
                            <td>PostgreSQL (existente)</td>
                            <td>Reutilizar infra, agregar tabla <code>ml_features</code></td>
                        </tr>
                        <tr>
                            <td><strong>Containerización</strong></td>
                            <td>Docker + Docker Compose</td>
                            <td>Consistencia dev/prod</td>
                        </tr>
                        <tr>
                            <td><strong>Monitoring</strong></td>
                            <td>Prometheus + Grafana</td>
                            <td>Métricas de ML (accuracy, latencia, drift)</td>
                        </tr>
                        <tr>
                            <td><strong>Entrenamiento</strong></td>
                            <td>Jupyter Notebooks</td>
                            <td>Experimentación rápida</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Estructura de Directorios</h3>
                <pre><code>parse/
├── ml-service/              # Servicio Python de ML
│   ├── app/
│   │   ├── main.py         # FastAPI app
│   │   ├── models/         # Modelos ML
│   │   │   ├── classifier.py
│   │   │   ├── ner_model.py
│   │   │   └── anomaly_detector.py
│   │   └── utils/
│   ├── training/           # Scripts de entrenamiento
│   │   ├── train_classifier.py
│   │   ├── train_ner.py
│   │   └── train_anomaly.py
│   ├── notebooks/          # Jupyter notebooks
│   ├── data/               # Datasets
│   ├── models/             # Modelos guardados (.h5, .pkl)
│   ├── tests/
│   ├── Dockerfile
│   └── requirements.txt
│
├── backend/                # Backend Node.js existente
│   └── src/
│       └── services/
│           └── mlService.js  # Cliente para ML service
│
└── docker-compose.yml      # Orquestación completa
</code></pre>
            </section>

            <!-- Métricas y Evaluación -->
            <section class="section">
                <h2>📊 Métricas y Evaluación</h2>

                <h3>Métricas por Modelo</h3>

                <div class="grid">
                    <div class="box">
                        <h4>Clasificador</h4>
                        <ul>
                            <li><strong>Accuracy:</strong> >95%</li>
                            <li><strong>Precision por clase:</strong> >90%</li>
                            <li><strong>Recall por clase:</strong> >90%</li>
                            <li><strong>F1-Score:</strong> >92%</li>
                            <li><strong>Matriz de confusión:</strong> Análisis de errores</li>
                        </ul>
                    </div>
                    <div class="box">
                        <h4>NER</h4>
                        <ul>
                            <li><strong>Entity-level Precision:</strong> >90%</li>
                            <li><strong>Entity-level Recall:</strong> >85%</li>
                            <li><strong>CUIT Detection:</strong> >98%</li>
                            <li><strong>Date Detection:</strong> >95%</li>
                            <li><strong>Amount Detection:</strong> >92%</li>
                        </ul>
                    </div>
                    <div class="box">
                        <h4>Anomaly Detection</h4>
                        <ul>
                            <li><strong>False Positive Rate:</strong> <5%</li>
                            <li><strong>True Positive Rate:</strong> >80%</li>
                            <li><strong>Precision:</strong> >75%</li>
                            <li><strong>Latencia:</strong> <100ms</li>
                        </ul>
                    </div>
                </div>

                <h3>Monitoreo Continuo</h3>
                <div class="card info">
                    <h4>Métricas en Producción</h4>
                    <ul>
                        <li><strong>Model Drift:</strong> Monitorear distribución de inputs vs training</li>
                        <li><strong>Prediction Distribution:</strong> Verificar balance de clases predichas</li>
                        <li><strong>Confidence Score:</strong> Tracking de confianza promedio</li>
                        <li><strong>User Corrections:</strong> Feedback loop cuando usuarios corrigen</li>
                        <li><strong>Latency:</strong> p50, p95, p99 de tiempo de respuesta</li>
                    </ul>
                </div>

                <h3>Estrategia de Reentrenamiento</h3>
                <div class="card warning">
                    <h4>Cuándo Reentrenar</h4>
                    <ol>
                        <li><strong>Cada 3 meses:</strong> Reentrenamiento scheduled con datos nuevos</li>
                        <li><strong>Accuracy drop >5%:</strong> Reentrenamiento de emergencia</li>
                        <li><strong>Nuevo tipo de documento:</strong> Expandir dataset y reentrenar</li>
                        <li><strong>Feedback acumulado:</strong> >500 correcciones de usuarios</li>
                    </ol>
                </div>
            </section>

            <!-- Costos y Recursos -->
            <section class="section">
                <h2>💰 Costos y Recursos</h2>

                <h3>Costos de Implementación</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Concepto</th>
                            <th>Costo</th>
                            <th>Notas</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ML Engineer (3 meses)</td>
                            <td>Variable</td>
                            <td>Desarrollo y entrenamiento</td>
                        </tr>
                        <tr>
                            <td>Etiquetado de datos</td>
                            <td>$500-2000</td>
                            <td>Depende de volumen, puede ser interno</td>
                        </tr>
                        <tr>
                            <td>GPU Training (Colab Pro+)</td>
                            <td>$50/mes x 2 meses</td>
                            <td>Para entrenamiento de CNNs</td>
                        </tr>
                        <tr>
                            <td>MLflow Hosting</td>
                            <td>$20-50/mes</td>
                            <td>Puede ser self-hosted</td>
                        </tr>
                    </tbody>
                </table>

                <h3>Costos Operacionales</h3>
                <table>
                    <thead>
                        <tr>
                            <th>Concepto</th>
                            <th>Costo Mensual</th>
                            <th>Notas</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>ML Service Server (CPU)</td>
                            <td>$50-100</td>
                            <td>4 vCPU, 8GB RAM</td>
                        </tr>
                        <tr>
                            <td>Storage (modelos + features)</td>
                            <td>$10-20</td>
                            <td>~50GB</td>
                        </tr>
                        <tr>
                            <td>Monitoring (Prometheus/Grafana)</td>
                            <td>$20-40</td>
                            <td>Puede ser self-hosted gratis</td>
                        </tr>
                        <tr>
                            <td><strong>Total Operacional</strong></td>
                            <td><strong>$80-160/mes</strong></td>
                            <td>Escalable según volumen</td>
                        </tr>
                    </tbody>
                </table>

                <h3>ROI Esperado</h3>
                <div class="card success">
                    <h4>Ahorros Estimados</h4>
                    <ul>
                        <li><strong>Reducción de intervención manual:</strong> 70% → ahorro de 10-15 horas/semana</li>
                        <li><strong>Menos errores:</strong> 95% accuracy vs 80% actual → menos reprocesos</li>
                        <li><strong>Detección temprana de fraudes:</strong> $5000-20000/año en facturas inválidas evitadas</li>
                        <li><strong>Costos de API Gemini:</strong> Reducción del 40% (solo fallback)</li>
                    </ul>
                    <p><strong>ROI break-even:</strong> 3-6 meses</p>
                </div>
            </section>

            <!-- Riesgos y Mitigaciones -->
            <section class="section">
                <h2>⚠️ Riesgos y Mitigaciones</h2>

                <table>
                    <thead>
                        <tr>
                            <th>Riesgo</th>
                            <th>Probabilidad</th>
                            <th>Impacto</th>
                            <th>Mitigación</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Insuficientes datos de entrenamiento</td>
                            <td><span class="badge medium">Media</span></td>
                            <td>Alto</td>
                            <td>Data augmentation, transfer learning, synthetic data</td>
                        </tr>
                        <tr>
                            <td>Modelos con accuracy <90%</td>
                            <td><span class="badge low">Baja</span></td>
                            <td>Medio</td>
                            <td>Fallback a Gemini, mejora iterativa</td>
                        </tr>
                        <tr>
                            <td>Latencia alta (>1s)</td>
                            <td><span class="badge medium">Media</span></td>
                            <td>Medio</td>
                            <td>Model optimization, caching, batch processing</td>
                        </tr>
                        <tr>
                            <td>Model drift en producción</td>
                            <td><span class="badge high">Alta</span></td>
                            <td>Alto</td>
                            <td>Monitoreo continuo, alertas, reentrenamiento scheduled</td>
                        </tr>
                        <tr>
                            <td>Costos operacionales altos</td>
                            <td><span class="badge low">Baja</span></td>
                            <td>Medio</td>
                            <td>Optimización de modelos, serverless options</td>
                        </tr>
                        <tr>
                            <td>Falta de expertise ML en equipo</td>
                            <td><span class="badge medium">Media</span></td>
                            <td>Alto</td>
                            <td>Capacitación, documentación exhaustiva, consultor externo</td>
                        </tr>
                    </tbody>
                </table>
            </section>

            <!-- Conclusiones -->
            <section class="section">
                <h2>✅ Conclusiones y Próximos Pasos</h2>

                <div class="card success">
                    <h4>Beneficios Clave</h4>
                    <ul>
                        <li>✅ Reducción del 70% en intervención manual</li>
                        <li>✅ Accuracy >95% en clasificación y extracción</li>
                        <li>✅ Detección automática de anomalías y fraudes</li>
                        <li>✅ Aprendizaje continuo con feedback loop</li>
                        <li>✅ Reducción de costos de APIs externas (Gemini)</li>
                        <li>✅ Mejor experiencia de usuario (más rápido, más preciso)</li>
                    </ul>
                </div>

                <div class="card info">
                    <h4>Próximos Pasos Inmediatos</h4>
                    <ol>
                        <li><strong>Validar viabilidad:</strong> Analizar datos existentes en <code>parse_db</code></li>
                        <li><strong>Definir MVP:</strong> Empezar solo con clasificador (caso de uso más simple)</li>
                        <li><strong>Preparar dataset:</strong> Exportar y etiquetar 1000+ documentos</li>
                        <li><strong>Proof of Concept:</strong> Entrenar clasificador básico en 1 semana</li>
                        <li><strong>Evaluar resultados:</strong> Si accuracy >90%, proceder con roadmap completo</li>
                    </ol>
                </div>

                <div class="highlight">
                    <h4>Recomendación</h4>
                    <p>Implementar en fases, comenzando con el <strong>clasificador de documentos</strong> como MVP. Si tiene éxito (accuracy >90%), expandir a NER y detección de anomalías. Esta aproximación reduce riesgos y permite validar el valor del ML antes de invertir en el stack completo.</p>
                </div>
            </section>

            <!-- Referencias -->
            <section class="section">
                <h2>📚 Referencias y Recursos</h2>

                <h3>Tutoriales y Documentación</h3>
                <ul>
                    <li><a href="https://spacy.io/usage/training" target="_blank">spaCy - Custom NER Training</a></li>
                    <li><a href="https://www.tensorflow.org/tutorials/images/classification" target="_blank">TensorFlow - Image Classification</a></li>
                    <li><a href="https://fastapi.tiangolo.com/" target="_blank">FastAPI - Modern Python API</a></li>
                    <li><a href="https://mlflow.org/docs/latest/quickstart.html" target="_blank">MLflow - Model Management</a></li>
                    <li><a href="https://scikit-learn.org/stable/modules/outlier_detection.html" target="_blank">scikit-learn - Anomaly Detection</a></li>
                </ul>

                <h3>Papers Relevantes</h3>
                <ul>
                    <li><strong>Document Classification:</strong> "Attention-based CNN for Document Classification"</li>
                    <li><strong>NER en Español:</strong> "BETO: Spanish BERT for NLP Tasks"</li>
                    <li><strong>Anomaly Detection:</strong> "Isolation Forest Algorithm"</li>
                    <li><strong>OCR Post-Processing:</strong> "Neural Machine Translation for OCR Error Correction"</li>
                </ul>

                <h3>Datasets Públicos</h3>
                <ul>
                    <li><strong>FUNSD:</strong> Form Understanding in Noisy Scanned Documents</li>
                    <li><strong>SROIE:</strong> Scanned Receipts OCR and Information Extraction</li>
                    <li><strong>Invoices Dataset:</strong> Kaggle - Invoice Entity Extraction</li>
                </ul>
            </section>
        </div>

        <footer>
            <p><strong>Parse - Machine Learning Implementation Guide</strong></p>
            <p>Última actualización: Noviembre 2025 | Versión 1.0</p>
            <p>Para consultas técnicas, contactar al equipo de desarrollo</p>
        </footer>
    </div>
</body>
</html>
