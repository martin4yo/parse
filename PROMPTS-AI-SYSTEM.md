# Sistema de Prompts Editables de IA

## âœ… ImplementaciÃ³n Completa

Se ha implementado un sistema completo para gestionar prompts de IA sin modificar cÃ³digo:

### ğŸ“‹ Componentes Creados

1. **Modelo de Base de Datos** (`schema.prisma`)
   - Tabla `ai_prompts` con soporte multi-tenant
   - Versionado automÃ¡tico
   - MÃ©tricas de uso (tasa de Ã©xito, veces usado)
   - Soporte para diferentes motores (OpenAI, Gemini, Claude, Ollama)

2. **Servicio PromptManager** (`services/promptManager.js`)
   - Cache en memoria (TTL: 5 minutos configurables)
   - Sistema de fallback (tenant â†’ global)
   - Reemplazo de variables `{{variable}}`
   - MÃ©tricas automÃ¡ticas de rendimiento

3. **API REST** (`routes/prompts.js`)
   - `GET /api/prompts` - Listar prompts
   - `POST /api/prompts` - Crear prompt
   - `PUT /api/prompts/:id` - Actualizar prompt
   - `DELETE /api/prompts/:id` - Eliminar prompt
   - `POST /api/prompts/test` - Probar prompt con variables
   - `GET /api/prompts/stats/cache` - EstadÃ­sticas del cache
   - `POST /api/prompts/cache/clear` - Limpiar cache

4. **Seed de Prompts** (`prisma/seeds/prompts.js`)
   - MigraciÃ³n automÃ¡tica de prompts hardcodeados
   - 5 prompts pre-configurados:
     - ExtracciÃ³n facturas (OpenAI, Claude, Gemini, Ollama)
     - ExtracciÃ³n resÃºmenes de tarjeta

## ğŸš€ PrÃ³ximos Pasos

### 1. Aplicar MigraciÃ³n de Prisma

```bash
cd backend
npx prisma migrate dev --name add_ai_prompts
npx prisma generate
```

### 2. Ejecutar Seed de Prompts

```bash
node prisma/seeds/prompts.js
```

### 3. Actualizar Funciones de ExtracciÃ³n

**YA ACTUALIZADO:** `extractWithOpenAI` ya usa PromptManager

**PENDIENTE - Actualizar estas funciones en `documentProcessor.js`:**

```javascript
// extractWithClaude (lÃ­nea ~294)
async extractWithClaude(text, tenantId = null) {
  try {
    const Anthropic = require('@anthropic-ai/sdk');
    const anthropic = new Anthropic({
      apiKey: process.env.ANTHROPIC_API_KEY,
    });

    const prompt = await promptManager.getPromptText(
      'EXTRACCION_FACTURA_CLAUDE',
      { text },
      tenantId,
      'anthropic'
    );

    if (!prompt) {
      console.error('âŒ Prompt EXTRACCION_FACTURA_CLAUDE no encontrado');
      return null;
    }

    const response = await anthropic.messages.create({
      model: 'claude-3-haiku-20240307',
      max_tokens: 300,
      messages: [{ role: 'user', content: prompt }],
    });

    const result = JSON.parse(response.content[0].text);
    await promptManager.registrarResultado('EXTRACCION_FACTURA_CLAUDE', true, tenantId);
    return result;
  } catch (error) {
    console.error('Error with Claude extraction:', error);
    await promptManager.registrarResultado('EXTRACCION_FACTURA_CLAUDE', false, tenantId).catch(() => {});
    return null;
  }
}

// extractWithGemini (lÃ­nea ~402)
async extractWithGemini(text, tenantId = null, retries = 0) {
  for (let attempt = 0; attempt <= retries; attempt++) {
    try {
      const { GoogleGenerativeAI } = require('@google/generative-ai');
      const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
      const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });

      const prompt = await promptManager.getPromptText(
        'EXTRACCION_FACTURA_GEMINI',
        { text },
        tenantId,
        'gemini'
      );

      if (!prompt) {
        console.error('âŒ Prompt EXTRACCION_FACTURA_GEMINI no encontrado');
        return null;
      }

      const result = await model.generateContent(prompt);
      let jsonText = result.response.text();

      // Limpiar respuesta (mantener lÃ³gica existente)
      jsonText = jsonText
        .replace(/```json\n?/g, '')
        .replace(/\n?```/g, '')
        .replace(/^[^{]*{/, '{')
        .replace(/}[^}]*$/, '}')
        .replace(/\/\/.*$/gm, '')
        .replace(/\/\*[\s\S]*?\*\//g, '')
        .trim();

      const data = JSON.parse(jsonText);
      await promptManager.registrarResultado('EXTRACCION_FACTURA_GEMINI', true, tenantId);
      return data;

    } catch (error) {
      console.error(`Error with Gemini extraction (attempt ${attempt + 1}):`, error);

      if (error.status === 503 && attempt < retries) {
        const delay = Math.pow(2, attempt) * 1000;
        console.log(`Gemini service unavailable, retrying in ${delay}ms...`);
        await new Promise(resolve => setTimeout(resolve, delay));
        continue;
      }

      if (attempt === retries) {
        await promptManager.registrarResultado('EXTRACCION_FACTURA_GEMINI', false, tenantId).catch(() => {});
        return null;
      }
    }
  }
  return null;
}

// extractResumenTarjetaWithAI (lÃ­nea ~1684)
async extractResumenTarjetaWithAI(text, tenantId = null) {
  try {
    const limitedText = text.substring(0, 10000);

    const prompt = await promptManager.getPromptText(
      'EXTRACCION_RESUMEN_TARJETA',
      { text: limitedText },
      tenantId
    );

    if (!prompt) {
      console.error('âŒ Prompt EXTRACCION_RESUMEN_TARJETA no encontrado');
      return null;
    }

    // Intentar con Gemini primero
    if (process.env.GEMINI_API_KEY && process.env.GEMINI_API_KEY !== 'tu-api-key-aqui') {
      try {
        console.log('ğŸ¤– [RESUMEN TARJETA] Intentando con Gemini...');
        const { GoogleGenerativeAI } = require('@google/generative-ai');
        const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
        const model = genAI.getGenerativeModel({ model: 'gemini-1.5-flash' });

        const result = await model.generateContent(prompt);
        let jsonText = result.response.text();

        // Limpiar respuesta
        jsonText = jsonText
          .replace(/```json\n?/g, '')
          .replace(/\n?```/g, '')
          .replace(/^[^{]*{/, '{')
          .replace(/}[^}]*$/, '}')
          .replace(/\/\/.*$/gm, '')
          .replace(/\/\*[\s\S]*?\*\//g, '')
          .trim();

        const data = JSON.parse(jsonText);

        if (data.metadata && data.transacciones && Array.isArray(data.transacciones)) {
          await promptManager.registrarResultado('EXTRACCION_RESUMEN_TARJETA', true, tenantId);
          return data;
        }
      } catch (error) {
        console.error('âš ï¸ [RESUMEN TARJETA] Error con Gemini:', error.message);
      }
    }

    // Intentar con Anthropic como fallback
    if (process.env.ANTHROPIC_API_KEY && process.env.ANTHROPIC_API_KEY !== 'tu-api-key-aqui') {
      try {
        console.log('ğŸ¤– [RESUMEN TARJETA] Intentando con Anthropic...');
        const Anthropic = require('@anthropic-ai/sdk');
        const anthropic = new Anthropic({
          apiKey: process.env.ANTHROPIC_API_KEY,
        });

        const message = await anthropic.messages.create({
          model: 'claude-3-haiku-20240307',
          max_tokens: 2048,
          messages: [{
            role: 'user',
            content: prompt
          }]
        });

        const responseText = message.content[0].text;
        let jsonText = responseText;
        const jsonMatch = responseText.match(/\{[\s\S]*\}/);
        if (jsonMatch) {
          jsonText = jsonMatch[0];
        }

        const data = JSON.parse(jsonText);

        if (data.metadata && data.transacciones && Array.isArray(data.transacciones)) {
          await promptManager.registrarResultado('EXTRACCION_RESUMEN_TARJETA', true, tenantId);
          return data;
        }
      } catch (error) {
        console.error('âš ï¸ [RESUMEN TARJETA] Error con Anthropic:', error.message);
      }
    }

    await promptManager.registrarResultado('EXTRACCION_RESUMEN_TARJETA', false, tenantId);
    return null;

  } catch (error) {
    console.error('Error in extractResumenTarjetaWithAI:', error);
    await promptManager.registrarResultado('EXTRACCION_RESUMEN_TARJETA', false, tenantId).catch(() => {});
    return null;
  }
}
```

### 4. Pasar tenantId a las Funciones de ExtracciÃ³n

En los lugares donde se llama a las funciones de extracciÃ³n (ej: `routes/documentos.js`), pasar el `tenantId`:

```javascript
// Antes
const data = await processor.extractWithGemini(text);

// DespuÃ©s
const data = await processor.extractWithGemini(text, req.tenantId);
```

## ğŸ“Š Uso del Sistema

### API Ejemplos

#### Listar Prompts
```bash
curl http://localhost:5050/api/prompts \
  -H "Authorization: Bearer TOKEN"
```

#### Crear Prompt Personalizado (por tenant)
```bash
curl -X POST http://localhost:5050/api/prompts \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer TOKEN" \
  -d '{
    "clave": "EXTRACCION_FACTURA_GEMINI",
    "nombre": "ExtracciÃ³n Personalizada Tenant X",
    "prompt": "Mi prompt personalizado con {{text}}",
    "descripcion": "VersiÃ³n customizada para mi empresa",
    "motor": "gemini",
    "variables": {
      "text": "Texto del documento"
    }
  }'
```

#### Probar Prompt
```bash
curl -X POST http://localhost:5050/api/prompts/test \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer TOKEN" \
  -d '{
    "clave": "EXTRACCION_FACTURA_GEMINI",
    "variables": {
      "text": "Texto de prueba..."
    },
    "motor": "gemini"
  }'
```

#### Ver EstadÃ­sticas del Cache
```bash
curl http://localhost:5050/api/prompts/stats/cache \
  -H "Authorization: Bearer TOKEN"
```

## ğŸ¯ Beneficios

1. **Sin Modificar CÃ³digo**: Prompts editables desde API/UI
2. **Multi-tenant**: Cada cliente puede tener sus propios prompts
3. **Versionado**: Historial automÃ¡tico de cambios
4. **Performance**: Cache en memoria con TTL configurable
5. **MÃ©tricas**: Tasa de Ã©xito automÃ¡tica
6. **Fallback**: Sistema de tenant â†’ global
7. **Variables**: Reemplazo dinÃ¡mico tipo `{{variable}}`

## ğŸ”§ Variables de Entorno

```env
# Cache de prompts (opcional)
PROMPT_CACHE_TTL=300000  # 5 minutos en ms (default)
```

## ğŸ“ Variables Disponibles en Prompts

- `{{text}}` - Texto completo del documento
- (Puedes agregar mÃ¡s segÃºn necesites)

## ğŸš€ UI Futura (Recomendado)

Crear en el frontend:
- PÃ¡gina `/admin/prompts` con lista de prompts
- Editor de prompts con preview
- Selector de motor de IA
- ComparaciÃ³n de versiones
- MÃ©tricas visuales (grÃ¡ficos de tasa de Ã©xito)
- Test en tiempo real

## âœ¨ Estructura Final

```
backend/
â”œâ”€â”€ prisma/
â”‚   â”œâ”€â”€ schema.prisma         # âœ… Modelo ai_prompts agregado
â”‚   â””â”€â”€ seeds/
â”‚       â””â”€â”€ prompts.js         # âœ… Seed de prompts
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ promptManager.js   # âœ… Gestor con cache
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â””â”€â”€ prompts.js         # âœ… API REST
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ documentProcessor.js # ğŸ”„ Actualizar funciones restantes
â”‚   â””â”€â”€ index.js               # âœ… Rutas registradas
```

## ğŸ‰ Â¡Listo!

El sistema estÃ¡ funcionalmente completo. Solo falta:
1. Aplicar migraciÃ³n
2. Ejecutar seed
3. Actualizar las funciones restantes de documentProcessor.js
4. (Opcional) Crear UI de administraciÃ³n
