# ‚úÖ Checklist de Despliegue a Producci√≥n

**Fecha de creaci√≥n**: Noviembre 4, 2025
**Versi√≥n**: 1.1.0 (con optimizaci√≥n Sharp + Pipeline Claude Vision)

---

## üîç PRE-DESPLIEGUE: Verificaciones Locales

### ‚úÖ C√≥digo

- [x] **Sintaxis verificada**: Todos los archivos pasan `node -c`
- [x] **Dependencias instaladas**: Sharp, pdf2pic, todos los m√≥dulos
- [x] **Tests pasando**: Script de verificaci√≥n ejecutado exitosamente
- [x] **No hay console.log sensibles**: Contrase√±as, API keys, etc.
- [x] **Variables de entorno documentadas**: `.env.example` actualizado
- [x] **Try-catch balanceados**: Todos los async tienen manejo de errores

### ‚úÖ Funcionalidades Nuevas

- [x] **Image Optimization Service**: Creado y testeado
- [x] **Claude Vision Pipeline**: Integrado con clasificador
- [x] **Limpieza autom√°tica**: Hook en documentos.js
- [x] **Tests actualizados**: test-claude-vision.js, test-image-optimization.js
- [x] **Documentaci√≥n completa**: IMPLEMENTACION-SHARP-OPTIMIZATION.md, FIX-CLAUDE-VISION-PIPELINE.md

### ‚úÖ Base de Datos

- [ ] **Schema actualizado**: Verificar que Prisma schema est√° sincronizado
- [ ] **Migraciones**: `prisma migrate deploy` listo para ejecutar
- [ ] **Backups**: Backup reciente de BD antes de deploy

```bash
# Verificar estado
cd backend
npx prisma migrate status

# Si hay pendientes
npx prisma migrate deploy
```

---

## üì¶ PREPARACI√ìN PARA PRODUCCI√ìN

### 1. Variables de Entorno

Verificar que **TODAS** estas variables est√©n configuradas en producci√≥n:

#### **Cr√≠ticas (Obligatorias)**
```env
# Base de datos
DATABASE_URL="postgresql://user:pass@host:5432/parse_db"

# Puerto
PORT=5050

# Seguridad
JWT_SECRET="tu-secret-muy-seguro-aqui"
NODE_ENV=production

# CORS
CORS_ORIGIN=https://tu-dominio.com
```

#### **IA (Recomendadas)**
```env
# Google Gemini
GEMINI_API_KEY=tu-api-key
ENABLE_AI_EXTRACTION=true

# Claude Vision (Nuevo)
ANTHROPIC_API_KEY=tu-api-key
USE_CLAUDE_VISION=true

# Document AI (Opcional)
USE_DOCUMENT_AI=false
GOOGLE_APPLICATION_CREDENTIALS=/path/to/credentials.json
GCP_PROJECT_ID=tu-proyecto
DOCUMENT_AI_PROCESSOR_ID=tu-processor-id
DOCUMENT_AI_LOCATION=us
```

### 2. Archivos a Subir

**Incluir:**
```
backend/
  ‚îú‚îÄ‚îÄ src/
  ‚îÇ   ‚îú‚îÄ‚îÄ services/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ imageOptimizationService.js ‚≠ê NUEVO
  ‚îÇ   ‚îú‚îÄ‚îÄ lib/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ documentProcessor.js ‚≠ê MODIFICADO
  ‚îÇ   ‚îú‚îÄ‚îÄ routes/
  ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ documentos.js ‚≠ê MODIFICADO
  ‚îÇ   ‚îî‚îÄ‚îÄ scripts/
  ‚îÇ       ‚îú‚îÄ‚îÄ test-image-optimization.js ‚≠ê NUEVO
  ‚îÇ       ‚îú‚îÄ‚îÄ test-claude-vision.js ‚≠ê MODIFICADO
  ‚îÇ       ‚îî‚îÄ‚îÄ verify-production.js ‚≠ê NUEVO
  ‚îú‚îÄ‚îÄ package.json
  ‚îú‚îÄ‚îÄ package-lock.json
  ‚îî‚îÄ‚îÄ prisma/

CLAUDE.md ‚≠ê MODIFICADO
IMPLEMENTACION-SHARP-OPTIMIZATION.md ‚≠ê NUEVO
FIX-CLAUDE-VISION-PIPELINE.md ‚≠ê NUEVO
CHECKLIST-PRODUCCION.md ‚≠ê NUEVO (este archivo)
```

**NO incluir:**
```
.env
node_modules/
uploads/ (archivos, pero s√≠ el directorio vac√≠o)
*.log
.git/ (opcional seg√∫n estrategia)
```

### 3. Permisos de Archivos

```bash
# Directorio uploads debe ser escribible
chmod 755 backend/uploads

# Scripts deben ser ejecutables
chmod +x backend/src/scripts/*.js

# .env debe ser solo lectura para el owner
chmod 600 backend/.env
```

---

## üöÄ DESPLIEGUE PASO A PASO

### PASO 1: Backup de Producci√≥n

```bash
# 1. Backup de base de datos
pg_dump -h HOST -U USER parse_db > backup_pre_deploy_$(date +%Y%m%d_%H%M%S).sql

# 2. Backup de uploads (si hay archivos importantes)
tar -czf uploads_backup_$(date +%Y%m%d_%H%M%S).tar.gz backend/uploads/

# 3. Backup del c√≥digo actual
tar -czf code_backup_$(date +%Y%m%d_%H%M%S).tar.gz backend/
```

### PASO 2: Detener Servicios

```bash
# Si usas PM2
pm2 stop parse-backend

# Si usas systemd
sudo systemctl stop parse-backend

# Verificar que se detuvo
pm2 list
# o
sudo systemctl status parse-backend
```

### PASO 3: Actualizar C√≥digo

```bash
# Opci√≥n A: Git pull
cd /ruta/a/produccion
git pull origin master

# Opci√≥n B: Subir archivos manualmente
scp -r backend/ user@servidor:/ruta/a/produccion/

# Opci√≥n C: FTP/SFTP
# (usar cliente FTP)
```

### PASO 4: Instalar Dependencias

```bash
cd backend

# IMPORTANTE: Asegurarse que Sharp se compile para el servidor de producci√≥n
npm install --production

# Si hay problemas con Sharp
npm rebuild sharp

# Verificar Sharp
node -e "const sharp = require('sharp'); console.log('Sharp version:', sharp.versions);"
```

### PASO 5: Ejecutar Migraciones

```bash
cd backend

# Ver estado de migraciones
npx prisma migrate status

# Aplicar migraciones pendientes
npx prisma migrate deploy

# Regenerar cliente Prisma
npx prisma generate
```

### PASO 6: Verificar Configuraci√≥n

```bash
# Ejecutar script de verificaci√≥n
node src/scripts/verify-production.js

# Debe mostrar:
# ‚úÖ ‚úÖ ‚úÖ TODAS LAS VERIFICACIONES PASARON ‚úÖ ‚úÖ ‚úÖ
```

### PASO 7: Iniciar Servicios

```bash
# Si usas PM2
pm2 start ecosystem.config.js
pm2 save

# Si usas systemd
sudo systemctl start parse-backend
sudo systemctl status parse-backend

# Verificar logs
pm2 logs parse-backend --lines 50
# o
sudo journalctl -u parse-backend -f
```

### PASO 8: Smoke Tests

```bash
# 1. Verificar que el servidor responde
curl http://localhost:5050/health
# Debe retornar: {"status":"ok"}

# 2. Verificar API
curl http://localhost:5050/api/health
# Debe retornar JSON con status

# 3. Test de upload (opcional)
# Subir un documento de prueba desde la UI
```

---

## ‚úÖ POST-DESPLIEGUE: Verificaciones

### Inmediatamente despu√©s (0-5 minutos)

- [ ] **Servidor responde**: Endpoint de health retorna 200
- [ ] **Logs sin errores**: No hay errores cr√≠ticos en logs
- [ ] **Base de datos conectada**: Queries funcionan
- [ ] **Uploads funciona**: Directorio es escribible

```bash
# Ver logs en tiempo real
pm2 logs parse-backend --lines 100

# Verificar errores
pm2 logs parse-backend --err --lines 50
```

### Primeras horas (0-2 horas)

- [ ] **Optimizaci√≥n Sharp funciona**: Ver logs de "‚úÖ Imagen optimizada"
- [ ] **Claude Vision con pipeline**: Ver logs de "PASO 1: CLASIFICACI√ìN"
- [ ] **Limpieza autom√°tica**: Ver logs de "üßπ Limpieza de archivos"
- [ ] **No hay memory leaks**: Monitorear uso de RAM
- [ ] **Performance OK**: Tiempos de respuesta similares o mejores

```bash
# Monitorear recursos
pm2 monit

# Ver estad√≠sticas
pm2 show parse-backend
```

### Primer d√≠a (0-24 horas)

- [ ] **Usuarios reportan mejora**: Menos errores de extracci√≥n
- [ ] **Costos API reducidos**: Verificar en consolas de Gemini/Claude
- [ ] **Archivos temporales limpios**: No crecimiento descontrolado en uploads/

```bash
# Ver tama√±o del directorio uploads
du -sh backend/uploads/

# Contar archivos temporales
find backend/uploads -name "*_optimized*" -o -name "*_enhanced*" | wc -l
# Deber√≠a ser 0 o muy bajo
```

---

## üêõ TROUBLESHOOTING

### Problema: Sharp no funciona en producci√≥n

**S√≠ntomas**: Error "sharp: command not found" o "Cannot find module 'sharp'"

**Soluci√≥n**:
```bash
# Desinstalar Sharp
npm uninstall sharp

# Limpiar cache
npm cache clean --force

# Reinstalar con build nativo
npm install --build-from-source sharp

# O usar prebuilt
npm install sharp

# Verificar
node -e "require('sharp')"
```

### Problema: Archivos temporales se acumulan

**S√≠ntomas**: Directorio uploads crece indefinidamente

**Soluci√≥n**:
```bash
# Limpiar manualmente
cd backend/uploads
find . -name "*_optimized*" -mtime +1 -delete
find . -name "*_enhanced*" -mtime +1 -delete
find . -name "processed_*" -mtime +1 -delete

# Verificar que hook de limpieza funciona
grep "cleanTempFiles" backend/src/routes/documentos.js
```

### Problema: Claude Vision no usa pipeline

**S√≠ntomas**: Logs no muestran "PASO 1: CLASIFICACI√ìN"

**Soluci√≥n**:
```bash
# Verificar que se pasa el texto
grep "extractWithClaudeVision.*text" backend/src/lib/documentProcessor.js

# Debe mostrar:
# const data = await this.extractWithClaudeVision(filePath, tenantId, text);
```

### Problema: Alta latencia

**S√≠ntomas**: Requests toman >10 segundos

**Soluci√≥n**:
```bash
# Verificar tama√±o de im√°genes en logs
# Debe mostrar reducci√≥n:
# "‚úÖ Imagen optimizada: 3.2 MB ‚Üí 0.6 MB"

# Si no hay reducci√≥n, verificar que imageOptimizationService est√° activo
node -e "const service = require('./backend/src/services/imageOptimizationService'); console.log(service);"
```

---

## üîÑ ROLLBACK (Si es necesario)

Si algo sale mal, seguir estos pasos para volver al estado anterior:

### Rollback R√°pido (C√≥digo)

```bash
# 1. Detener servicios
pm2 stop parse-backend

# 2. Restaurar c√≥digo del backup
cd /ruta/a/produccion
tar -xzf code_backup_YYYYMMDD_HHMMSS.tar.gz

# 3. Reinstalar dependencias de versi√≥n anterior
cd backend
npm install

# 4. Reiniciar
pm2 start parse-backend
```

### Rollback Base de Datos (Solo si hubo migraciones)

```bash
# 1. Restaurar backup
psql -h HOST -U USER parse_db < backup_pre_deploy_YYYYMMDD_HHMMSS.sql

# 2. Verificar
psql -h HOST -U USER -d parse_db -c "\dt"
```

### Rollback Git (Si usas Git)

```bash
# Ver √∫ltimos commits
git log --oneline -10

# Volver a commit anterior
git revert HEAD
# o
git reset --hard COMMIT_ANTERIOR

# Push (con cuidado)
git push --force origin master
```

---

## üìä M√âTRICAS A MONITOREAR

### Primeros 7 d√≠as

| M√©trica | Antes | Objetivo | C√≥mo Medir |
|---------|-------|----------|------------|
| Tasa de √©xito extracci√≥n | 85% | 95%+ | Logs de documentos procesados |
| Tiempo promedio proceso | 4s | 2s | Timestamps en logs |
| Tama√±o promedio archivo | 2.5 MB | 0.5 MB | Logs de optimizaci√≥n |
| Costo por documento | $0.003 | $0.001 | Consola Gemini/Claude |
| Uso de disco (uploads) | ? | <500 MB | `du -sh uploads/` |
| Memoria RAM | ? | <2 GB | `pm2 monit` |

### Queries √∫tiles para m√©tricas

```sql
-- Tasa de √©xito de extracci√≥n (√∫ltimas 24 horas)
SELECT
  estadoProcesamiento,
  COUNT(*) as total,
  ROUND(COUNT(*) * 100.0 / SUM(COUNT(*)) OVER(), 2) as porcentaje
FROM documentos_procesados
WHERE "createdAt" > NOW() - INTERVAL '24 hours'
GROUP BY estadoProcesamiento;

-- Tiempo promedio de procesamiento
SELECT
  AVG(EXTRACT(EPOCH FROM ("updatedAt" - "createdAt"))) as avg_seconds
FROM documentos_procesados
WHERE "createdAt" > NOW() - INTERVAL '24 hours'
  AND estadoProcesamiento = 'completado';

-- Documentos procesados por hora (√∫ltimas 24h)
SELECT
  DATE_TRUNC('hour', "createdAt") as hora,
  COUNT(*) as documentos
FROM documentos_procesados
WHERE "createdAt" > NOW() - INTERVAL '24 hours'
GROUP BY hora
ORDER BY hora DESC;
```

---

## üìû CONTACTOS DE EMERGENCIA

**Responsables del deploy**:
- Desarrollador: [Tu nombre/email]
- SysAdmin: [Nombre/email]
- DBA: [Nombre/email]

**Servicios externos**:
- Google Cloud Support: https://cloud.google.com/support
- Anthropic Support: support@anthropic.com
- Servidor: [IP/Proveedor]

---

## ‚úÖ CHECKLIST FINAL

Antes de dar por completado el deploy:

- [ ] C√≥digo actualizado en servidor
- [ ] Dependencias instaladas (incluyendo Sharp)
- [ ] Variables de entorno configuradas
- [ ] Migraciones ejecutadas
- [ ] Script de verificaci√≥n pas√≥
- [ ] Servicios iniciados correctamente
- [ ] Logs muestran "TODAS LAS VERIFICACIONES PASARON"
- [ ] Endpoint /health responde
- [ ] Test manual de upload funciona
- [ ] Logs muestran optimizaci√≥n de im√°genes
- [ ] Logs muestran pipeline de Claude Vision
- [ ] No hay errores en primeros 10 minutos
- [ ] Backup guardado en lugar seguro
- [ ] Documentaci√≥n actualizada
- [ ] Equipo notificado del deploy exitoso

---

## üìù NOTAS DEL DEPLOY

```
Fecha: ___/___/2025
Hora inicio: __:__
Hora fin: __:__
Responsable: __________
Versi√≥n: 1.1.0

Incidencias:
- Ninguna / [Describir]

Rollback necesario: S√≠ / No

Observaciones:
[Agregar notas relevantes]
```

---

**üéâ Si todos los checks est√°n en verde, el deploy fue exitoso!**

**Pr√≥ximos pasos**: Monitorear durante 24-48 horas y ajustar seg√∫n m√©tricas.
